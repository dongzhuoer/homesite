---
title: pre-convoluted features 终于成功了
author: Zhuoer Dong
date: '2019-08-09'
slug: pre-convoluted-features-终于成功了
categories: 2019
tags: []
authors: []
---

<script src="08-09-pre-convoluted-features-终于成功了_files/header-attrs/header-attrs.js"></script>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; } /* Alert */
code span.an { color: #008000; } /* Annotation */
code span.at { } /* Attribute */
code span.bu { } /* BuiltIn */
code span.cf { color: #0000ff; } /* ControlFlow */
code span.ch { color: #008080; } /* Char */
code span.cn { } /* Constant */
code span.co { color: #008000; } /* Comment */
code span.cv { color: #008000; } /* CommentVar */
code span.do { color: #008000; } /* Documentation */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.im { } /* Import */
code span.in { color: #008000; } /* Information */
code span.kw { color: #0000ff; } /* Keyword */
code span.op { } /* Operator */
code span.ot { color: #ff4000; } /* Other */
code span.pp { color: #ff4000; } /* Preprocessor */
code span.sc { color: #008080; } /* SpecialChar */
code span.ss { color: #008080; } /* SpecialString */
code span.st { color: #008080; } /* String */
code span.va { } /* Variable */
code span.vs { color: #008080; } /* VerbatimString */
code span.wa { color: #008000; font-weight: bold; } /* Warning */
</style>


<blockquote>
<p>一晃都有三个多月没有写日记了，看来维护 Zhuoer’s Empire 还是很困难啊。毕竟都忙着眼前的事，由此可见可重复研究的阻碍很大啊。</p>
</blockquote>
<blockquote>
<p>两个月后又把这篇 post 整理了一下，具体的 bug 已经很难重现了，唯一记得的就是当时真是浪费了我成吨的时间。</p>
</blockquote>
<p><em>Deep Learning with PyTorch</em> chapter5 教我 preconvlute VGG（only train fc layer），明明 freeze 卷积层参数可以有很好的准确度，但只要我先把 feature 算出来保存到 <code>.npz</code>，就一直上不了 70%。</p>
<p>本来放过去了，到 chapter8 又遇到这个问题。不用说，用 resnet 一样不行。搞得我过了好久都没把这本书看完。我甚至专门 train 出一个 95% 的模型，然后载入这个模型的参数之后再 pre convolute，还是不行。</p>
<p>今天终于终于找到原因了，一句话来说就是没有用 <code>model.eval()</code>。因为训练好的 model 是在 <code>eval()</code> 时最优，也就是 feature 提取得好，fc 分类也很好；而默认的 <code>train()</code> 会有 dropout，这时 feature 就不是最佳的了，只调整 fc 当然不会有很好的结果。</p>
<p>回想起来，我在 debug 的时候经常会 <code>test(model, valid_loader)</code>，这就使得模型进入了 eval 模式（而初始是 train 模式）。由于我的时间是片段化的，经常遇到刚才两个结果还是一样的，然后突然就不一样的情况，这还怎么 debug 嘛！</p>
<p>然而，当我熬夜想找到具体原因时，<code>model.eval()</code> 又不那么重要了。可能是白天探索时，有的模型是 <code>train()</code>，有的是 <code>eval()</code> 吧；也可能是我有时用 <code>model.training = training</code> 来代替 <code>model.eval()</code>，但两者不完全一样。</p>
<p>总之，我在之后的 script 中使用以下策略，成功地用 pre-convoluted features 训练出 98% 的模型：</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> torchvision.models.resnet34(pretrained <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># wrong way       都怪这本破书教我这种小聪明</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> torch.nn.Sequential(<span class="op">*</span><span class="bu">list</span>(model.children())[:<span class="op">-</span><span class="dv">1</span>]) </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># correct way     简单粗暴，大智如愚</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>model.fc <span class="op">=</span> torch.nn.Identity()</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># or you can use `model.register_forward_hook()` to extract intermediate result</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>() <span class="co"># add this line before you calculate pre-convoluted features</span></span></code></pre></div>
